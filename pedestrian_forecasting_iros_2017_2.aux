\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The performance of the presented algorithm captures the most probable routes that a pedestrian chooses. In this example which was captured at thirty frames per second, the presented algorithm took 0.0158s per frame in a Python implementation. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gates-1-2}{{1}{1}{The performance of the presented algorithm captures the most probable routes that a pedestrian chooses. In this example which was captured at thirty frames per second, the presented algorithm took 0.0158s per frame in a Python implementation. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory.\relax }{figure.caption.1}{}}
\citation{Helbing1992}
\citation{kalman1960new}
\citation{Schneider2013}
\citation{Kooji2014}
\citation{Ziebart2008}
\citation{Ziebart2009}
\citation{Kitani2012}
\citation{Xie2013}
\citation{Karasev2016}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Karasev2016}
\citation{Karasev2016}
\citation{Doucet2000}
\citation{Ballan2016}
\citation{Karasev2016}
\citation{Ballan2016}
\citation{Ballan2016}
\citation{Walker2014}
\citation{Walker2014}
\citation{Kitani2012}
\citation{Walker2014}
\citation{Karasev2016}
\citation{Ballan2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-A}Background}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-B}Contributions}{2}{subsection.1.2}}
\citation{Kitani2012}
\citation{Karasev2016}
\citation{Robicquet2016}
\citation{MTA}
\@writefile{toc}{\contentsline {section}{\numberline {II}Model}{3}{section.2}}
\newlabel{sec:model}{{II}{3}{Model}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}The Variables of the Model}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}The Sensor Model}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}The Agent Model}{3}{subsection.2.3}}
\newlabel{eq:ode}{{2}{3}{The Agent Model}{equation.2.2}{}}
\newlabel{eq:x_check | ksx}{{3}{4}{The Agent Model}{equation.2.3}{}}
\newlabel{eq:v | ksx}{{4}{4}{The Agent Model}{equation.2.4}{}}
\newlabel{eq:models}{{5}{4}{The Agent Model}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-D}The Full Model}{4}{subsection.2.4}}
\newlabel{eq:pgm}{{6}{4}{The Full Model}{equation.2.6}{}}
\newlabel{eq:decomposition}{{9}{4}{The Full Model}{equation.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Efficient Probability Propagation}{4}{section.3}}
\newlabel{sec:efficient}{{III}{4}{Efficient Probability Propagation}{section.3}{}}
\newlabel{eq:approximation 0}{{10}{4}{Efficient Probability Propagation}{equation.3.10}{}}
\newlabel{eq:convolve}{{13}{4}{Efficient Probability Propagation}{equation.3.13}{}}
\newlabel{eq:push forward}{{18}{4}{Efficient Probability Propagation}{equation.3.18}{}}
\citation{Leveque1992}
\citation{Gottlieb2001}
\newlabel{eq:approximation 1}{{19}{5}{Efficient Probability Propagation}{equation.3.19}{}}
\newlabel{thm:error}{{1}{5}{Efficient Probability Propagation}{thm.3.1}{}}
\newlabel{cor:error}{{1}{5}{Efficient Probability Propagation}{cor.1}{}}
\newlabel{eq:approximation 2}{{21}{5}{Efficient Probability Propagation}{equation.3.21}{}}
\newlabel{thm:symmetry}{{2}{5}{Efficient Probability Propagation}{thm.3.2}{}}
\newlabel{thm:main}{{3}{5}{Efficient Probability Propagation}{thm.3.3}{}}
\newlabel{eq:approximation 3}{{26}{5}{Efficient Probability Propagation}{equation.3.26}{}}
\citation{Robicquet2016}
\citation{FreyDueck2007}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Algorithm to Compute $\rho _t$.\relax }}{6}{algorithm.1}}
\newlabel{alg:1}{{1}{6}{Algorithm to Compute $\rho _t$.\relax }{algorithm.1}{}}
\newlabel{alg1:step2}{{4}{6}{Algorithm to Compute $\rho _t$.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Implementation and Experimental results}{6}{section.4}}
\newlabel{sec:implementation}{{IV}{6}{Implementation and Experimental results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Learning the Vector Fields}{6}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Learning $\qopname  \relax m{Pr}( x_0 \mid M)$ and $\qopname  \relax m{Pr}(M)$}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Learning the Measurement Model}{7}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Learning the Noise Model}{7}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-E}Evaluating Performance}{7}{subsection.4.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces We behave qualitatively and quantitatively better than kitani in this example. Our algorithm starts out with a dense distribution, which spreads with time, whereas Kitani et al.'s algorithm is very confident in its mistake.\relax }}{7}{figure.caption.2}}
\newlabel{fig:death-1-2}{{2}{7}{We behave qualitatively and quantitatively better than kitani in this example. Our algorithm starts out with a dense distribution, which spreads with time, whereas Kitani et al.'s algorithm is very confident in its mistake.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Here we see how Kitani et al.'s algorithm finds a local minimum and so never reaches the terminal point we give it. Our algorithm doesn't solve an optimization problem online, and so our algorithm avoids that pitfall.\relax }}{7}{figure.caption.3}}
\newlabel{fig:coupa-1-4}{{3}{7}{Here we see how Kitani et al.'s algorithm finds a local minimum and so never reaches the terminal point we give it. Our algorithm doesn't solve an optimization problem online, and so our algorithm avoids that pitfall.\relax }{figure.caption.3}{}}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{Helbing1992}{1}
\bibcite{kalman1960new}{2}
\bibcite{Schneider2013}{3}
\bibcite{Kooji2014}{4}
\bibcite{Ziebart2008}{5}
\bibcite{Ziebart2009}{6}
\bibcite{Kitani2012}{7}
\bibcite{Xie2013}{8}
\bibcite{Karasev2016}{9}
\bibcite{Doucet2000}{10}
\bibcite{Ballan2016}{11}
\bibcite{Walker2014}{12}
\bibcite{Robicquet2016}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces We predict this trajectory very well, and while Kitani et al. captures the same behaviour, however their motion model doesn't adequately keep up with the ground truth of the pedestrian.\relax }}{8}{figure.caption.4}}
\newlabel{fig:bookstore-1-2}{{4}{8}{We predict this trajectory very well, and while Kitani et al. captures the same behaviour, however their motion model doesn't adequately keep up with the ground truth of the pedestrian.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces We see that at all times we outperform Random Walk and Kitani et al.'s algorithm. The initial dip in Kitani et al.'s algorithm is due to their initial distribution being very sharp.\relax }}{8}{figure.caption.5}}
\newlabel{fig:auc_vs_time}{{5}{8}{We see that at all times we outperform Random Walk and Kitani et al.'s algorithm. The initial dip in Kitani et al.'s algorithm is due to their initial distribution being very sharp.\relax }{figure.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Runtimes\relax }}{8}{table.caption.6}}
\newlabel{tab:time}{{I}{8}{Runtimes\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{8}{section.5}}
\newlabel{sec:conclusion}{{V}{8}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{References}{8}{section*.8}}
\bibcite{MTA}{14}
